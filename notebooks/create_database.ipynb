{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    Settings,\n",
    "    Document,\n",
    "    StorageContext,\n",
    ")\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_sliding_window(text, max_tokens=512, overlap=50):\n",
    "    words = text.split()  # Giả sử mỗi từ là 1 token\n",
    "    chunks = []\n",
    "    start = 0\n",
    "\n",
    "    while start < len(words):\n",
    "        chunk = words[start : start + max_tokens]\n",
    "        chunks.append(\" \".join(chunk))\n",
    "        start += max_tokens - overlap  # Trượt cửa sổ với độ chồng lấn\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def load_and_process_json(json_path):  \n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    for item in data:\n",
    "        content = item.get(\"content\", \"\")\n",
    "        unit_info = f\"Unit: {item.get('unit')}\" if item.get('unit') else \"\"\n",
    "        section_info = f\"Section: {item.get('section')}\" if item.get('section') else \"\"\n",
    "        type_info = f\"Type: {item.get('type')}\" if item.get('type') else \"\"\n",
    "        \n",
    "        # Add \"passage: \" prefix for document content\n",
    "        enriched_text = f\"passage: {unit_info}\\n{section_info}\\n{type_info}\\n{content}\".strip()\n",
    "        \n",
    "        metadata = item.get(\"metadata\", {})\n",
    "        metadata.update({\n",
    "            \"id\": item.get(\"id\"),\n",
    "            \"unit\": item.get(\"unit\"),\n",
    "            \"section\": item.get(\"section\"),\n",
    "        })\n",
    "        \n",
    "        # Split text if it's too long\n",
    "        chunks = split_text_sliding_window(enriched_text, max_tokens=500, overlap=50)\n",
    "        \n",
    "        if len(chunks) > 1:\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                chunk_metadata = metadata.copy()\n",
    "                chunk_metadata.update({\n",
    "                    \"id\": f\"{metadata['id']}_chunk_{i}\",\n",
    "                })\n",
    "                doc = Document(text=chunk, metadata=chunk_metadata)\n",
    "                documents.append(doc)\n",
    "        else:\n",
    "            doc = Document(text=enriched_text, metadata=metadata)\n",
    "            documents.append(doc)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "def process_all_json_files(directory):\n",
    "    documents = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            documents.extend(load_and_process_json(file_path))\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir = \"/home/buma04/ai-tutor/data/book_content/\"\n",
    "documents = process_all_json_files(json_dir)\n",
    "lc_embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-small\"\n",
    ")\n",
    "embed_model = LangchainEmbedding(lc_embed_model)\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/buma04/ai-tutor/data/book_content/unit1_getting_started.json\"\n",
    "documents.extend(load_and_process_json(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d6b4f0fa694be6af931240524fc051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1078485e7954679b113126dadd0bf96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "# create client and a new collection\n",
    "# chromadb.EphemeralClient saves data in-memory.\n",
    "chroma_client = chromadb.PersistentClient(path=\"../chromadb\")\n",
    "\n",
    "# Delete collection if it exists\n",
    "try:\n",
    "    chroma_client.delete_collection(\"unit1_db\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "chroma_collection = chroma_client.create_collection(\"unit1_db\")\n",
    "\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# Create index\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    embed_model=embed_model,\n",
    "    storage_context=storage_context,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 10 is greater than number of elements in index 8, updating n_results = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Các tài liệu tương tự:\n",
      "Tài liệu #1 (Score: 0.7601767550815584):\n",
      "Metadata: {'page': '9', 'chunk_type': 'paragraph', 'related_chunks': 'unit_1_page_8_2, unit_1_page_9_1', 'id': 'unit_1_page_9_4', 'unit': '1. Life stories we admire', 'section': 'Getting Started'}\n",
      "Nội dung: passage: Unit: 1. Life stories we admire\n",
      "Section: Getting Started\n",
      "Type: text\n",
      "4 Complete the sentences based on the conversation.\n",
      "Dang Thuy Tram was a young surgeon. She (1) _________ her diary while she (2) _________ in a field hospital during the war. One day, she (3) _________ while she (4) _________ in the jungle. She was only 27 then. An American soldier (5) _________ her diary for many years before returning a copy to her family....\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Tài liệu #2 (Score: 0.7550540918152124):\n",
      "Metadata: {'page': '9', 'chunk_type': 'list', 'related_chunks': 'unit_1_page_8_2, unit_1_page_9_1', 'id': 'unit_1_page_9_3', 'unit': '1. Life stories we admire', 'section': 'Getting Started'}\n",
      "Nội dung: passage: Unit: 1. Life stories we admire\n",
      "Section: Getting Started\n",
      "Type: list\n",
      "3 Find words and a phrase in 1 with the following meanings.\n",
      "1 a _________ descriptions of things that have happened\n",
      "2 d_________ the end of somebody’s life\n",
      "3 d_________ to giving time, attention, etc. to something\n",
      "4 y_________ the period of time when a person is young...\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Tài liệu #3 (Score: 0.7507478938817211):\n",
      "Metadata: {'page': '10', 'chunk_type': 'overview', 'related_chunks': 'unit_1_page_9_3', 'id': 'unit_1_page_10_4', 'unit': '1. Life stories we admire', 'section': 'Getting Started'}\n",
      "Nội dung: passage: Unit: 1. Life stories we admire\n",
      "Section: Getting Started\n",
      "Type: text\n",
      "ACTIVITY 3\n",
      "Aim: To introduce words related to life stories and events.\n",
      "•\tHave Ss look at the first letter of each word. Explain that these words are related to life stories and events, and they are all in the conversation in 1.\n",
      "•\tAsk Ss to read the definitions and look for the words in the conversation.\n",
      "•\tIn weaker classes, provide the number of letters of each word.\n",
      "•\tCheck answers as a class.\n",
      "Key: 1. accounts\t2. death...\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Tài liệu #4 (Score: 0.7487313872338228):\n",
      "Metadata: {'page': '10', 'chunk_type': 'list', 'related_chunks': 'unit_1_page_9_2', 'id': 'unit_1_page_10_1', 'unit': '1. Life stories we admire', 'section': 'Getting Started'}\n",
      "Nội dung: passage: Unit: 1. Life stories we admire\n",
      "Section: Getting Started\n",
      "Type: list\n",
      "ACTIVITY 2\n",
      "Aim: To check Ss’ comprehension of the conversation.\n",
      "•\tAsk Ss to read the statements and underline the keywords in each one.\n",
      "•\tThen have them read the conversation again and locate the part that contains the information for each statement. Have them compare the information in the conversation with each statement to work out the correct answer, and explain the evidence used.\n",
      "•\tHave Ss work in pairs to discuss ...\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Tài liệu #5 (Score: 0.7475471367677388):\n",
      "Metadata: {'page': '8', 'chunk_type': 'overview', 'id': 'unit_1_page_8_1', 'unit': '1. Life stories we admire', 'section': 'Getting Started'}\n",
      "Nội dung: passage: Unit: 1. Life stories we admire\n",
      "Section: Getting Started\n",
      "Type: text\n",
      "This unit includes:\n",
      "LANGUAGE\n",
      "Pronunciation\n",
      "Diphthongs /eɪ/ and /aʊ/\n",
      "Vocabulary\n",
      "Phrases related to life stories\n",
      "Grammar\n",
      "Past simple vs. Past continuous\n",
      "SKILLS\n",
      "Reading: Reading for main ideas and specific information in an article about Steve Jobs’ life and achievements\n",
      "Speaking: Talking about the lives of two national heroes of Viet Nam\n",
      "Listening: Listening for main ideas and specific information in a talk about the life...\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Tài liệu #6 (Score: 0.7352547933254877):\n",
      "Metadata: {'page': '9', 'chunk_type': 'paragraph', 'related_chunks': 'unit_1_page_9_1', 'id': 'unit_1_page_9_2', 'unit': '1. Life stories we admire', 'section': 'Getting Started'}\n",
      "Nội dung: passage: Unit: 1. Life stories we admire\n",
      "Section: Getting Started\n",
      "Type: text\n",
      "2 Read the conversation again and circle the correct answer to complete each of the sentences.\n",
      "1. Dang Thuy Tram was born in Ha Noi/Hue.\n",
      "2. Tram wrote about/operated on injured soldiers during the war.\n",
      "3. She died when she was very young/old.\n",
      "4. An American soldier kept her diary for 27 years/more than three decades before returning a copy to her family....\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Tài liệu #7 (Score: 0.7336843337386544):\n",
      "Metadata: {'page': '10', 'chunk_type': 'overview', 'related_chunks': 'unit_1_page_9_4', 'id': 'unit_1_page_10_7', 'unit': '1. Life stories we admire', 'section': 'Getting Started'}\n",
      "Nội dung: passage: Unit: 1. Life stories we admire\n",
      "Section: Getting Started\n",
      "Type: text\n",
      "ACTIVITY 4\n",
      "Aim: To help Ss identify the past simple and the past continuous.\n",
      "•\tTell Ss to read the summary and check understanding.\n",
      "•\tAsk Ss to complete the sentences, using words and phrases from the conversation in 1.\n",
      "•\tCheck answers as a class.\n",
      "•\tElicit the verb tenses, i.e. past simple and past continuous.\n",
      "Key: 1. wrote\t2. was working\t3. was killed\t4. was doing her duty\t5. kept...\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Tài liệu #8 (Score: 0.7257762606502464):\n",
      "Metadata: {'page': '8', 'chunk_type': 'dialogue', 'related_chunks': '', 'id': 'unit_1_page_8_2', 'unit': '1. Life stories we admire', 'section': 'Getting Started'}\n",
      "Nội dung: passage: Unit: 1. Life stories we admire\n",
      "Section: Getting Started\n",
      "Type: dialogue\n",
      "Audio script\n",
      "Mark: Hi, Nam. Your book must be very interesting. What are you reading?\n",
      "Nam: I’m reading a really good book in English called *Last Night I Dreamed of Peace: The Diary of Dang Thuy Tram*.\n",
      "Mark: Dang Thuy Tram? Who is she?\n",
      "Nam: She was born in Hue in 1942. She studied medicine in Ha Noi, and volunteered to join the army at the age of 24, working as a surgeon during the resistance war against the US.\n",
      "Mar...\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Tổng số tài liệu trong index: 8\n"
     ]
    }
   ],
   "source": [
    "# Truy xuất các tài liệu tương tự với một câu truy vấn\n",
    "retriever = index.as_retriever(similarity_top_k=10)\n",
    "retrieved_nodes = retriever.retrieve(\"query: \" + \"The dialogue in Section Getting Started Unit 1\")\n",
    "\n",
    "print(\"\\nCác tài liệu tương tự:\")\n",
    "for i, node in enumerate(retrieved_nodes):\n",
    "    print(f\"Tài liệu #{i+1} (Score: {node.score}):\")\n",
    "    print(f\"Metadata: {node.metadata}\")\n",
    "    print(f\"Nội dung: {node.text[:500]}...\\n\")\n",
    "    print(\"-\"*200)\n",
    "\n",
    "# Kiểm tra thông tin về index\n",
    "print(f\"\\nTổng số tài liệu trong index: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'unit_1_page_11_6', 'unit': 'Life stories we admire', 'section': 'READING', 'type': 'text', 'content': '2 Read the article. Choose the words or phrases with the closest meaning to the highlighted words or phrases in the text.\\nSTEVE JOBS’ LIFE AND ACHIEVEMENTS\\nA.\\nSteven Paul Jobs was born on 24 February, 1955 in San Francisco, USA. His biological parents were not married and gave him up for adoption. He was **adopted** by Clara and Paul Jobs. In 1971, Jobs met Steve Wozniak, who was five years older than him, but they bonded over their love of electronics. After high school, Jobs attended Reed College in Oregon, but found the classes boring and **dropped out** after six months.\\nB.\\nWhen Jobs was 21, he and Wozniak started Apple Computers in Jobs’ family garage with money they got by selling Jobs’ van and Wozniak’s scientific calculator. By making computers smaller, cheaper, and accessible to everyday users, their company became a huge success and sales quickly increased.\\nAlthough Jobs left Apple in 1985, he returned to his post in 1997 when the company needed new ideas. He helped invent new products such as the iMac, the iBook for students, the iPod music player, and iTunes music software. In 2007, he introduced the touch-screen iPhone which changed the way phones were used. Apple products were not only designed to be cutting-edge technology, but also to be stylish and easy to use.\\nIn addition, Jobs contributed to computer animation. In 1986, he bought a small company, which later became Pixar Animation Studios. It produced the first full-length computer-animated film *Toy Story*, followed by other blockbusters.\\nC.\\nIn 2003, Jobs was diagnosed with a rare form of pancreatic **cancer**. He fought the disease for several years, and stopped working in August, 2011. Two months later, he **passed away**. He had four children, three with his wife of 20 years and one from a previous relationship. On an Apple web page, a statement reads, ‘Apple has lost a visionary and creative **genius**, and the world has lost an amazing human being.\\n1. adopted\\nA. given birth to\\nB. taken by another family as their own child\\n2. dropped out\\nA. continued to study\\nB. left school/college before completing your studies\\n3. cancer\\nA. a serious disease\\nB. a dangerous animal\\n4. passed away\\nA. died\\nB. went past something\\n5. genius\\nA. a very intelligent person\\nB. an ordinary person’', 'metadata': {'page': '11', 'chunk_type': 'paragraph', 'related_chunks': '', 'id': 'unit_1_page_11_6', 'unit': 'Life stories we admire', 'section': 'READING'}}\n",
      "{'id': 'unit_1_page_15_4', 'unit': 'Life stories we admire', 'section': 'READING', 'type': 'list', 'content': 'ACTIVITY 2. While-reading\\nAim: To help Ss practise guessing the meaning of words and phrases from context.\\n•\\tAsk Ss to read the text and locate the highlighted words/ phrases in it.\\n•\\tAsk Ss to study the context of the word, i.e. the words before and after it, as well as the neighbouring sentences, e.g. 1. *The word ‘adopted’ is found after the sentence: His biological parents were not married and gave him up for adoption.*\\n•\\tEncourage Ss to replace the highlighted word/phrase with each answer choice to see which one fits in the sentence best, e.g. 1. *His biological parents were not married and gave him up for adoption. He was A. given birth to/B. taken by another family (Clara and Paul) as their own child. The answer choice B can replace the word ‘adopted’ without changing the meaning of the sentence. You can also ask if any words in the preceding sentence help guess the meaning, e.g. gave him up (handed him over to someone else).*\\n•\\tIn weaker classes, explain the meaning of any unknown vocabulary before and after the highlighted words/phrases.\\n•\\tHave Ss work in pairs to complete the activity.\\n•\\tCheck answers as a class.\\n•\\tConfirm understanding of the words and phrases by asking Ss to make sentences with them.\\nExam tips: Reading comprehension MCQs (for vocabulary)\\n1. Locate the word or phrase in the text.\\n2. Carefully study the context (i.e. the words that come before and after the item as well as the neighbouring sentences).\\n3. Try to replace the word/phrase with each answer choice to see which one fits the sentence without changing its meaning.\\nKey: 1. B\\t2. B\\t3. A\\t4. A\\t5. A\\nExtension: Put Ss in groups and have them come up with other forms or different collocations of the words and phrases, e.g. *adopt – to adopt a child/a pet, to adopt a method/a law/a name; adoption – put the baby for adoption; adopted – adopted son/daughter; adoptive – adoptive parents.* In stronger classes, encourage Ss to use them in sentences.', 'metadata': {'page': '15', 'chunk_type': 'activity', 'related_chunks': 'unit_1_page_11_6', 'id': 'unit_1_page_15_4', 'unit': 'Life stories we admire', 'section': 'READING'}}\n",
      "{'id': 'unit_1_page_26_2', 'unit': 'Life stories we admire', 'section': 'PROJECT', 'type': 'list', 'content': 'PROJECT\\nVISUAL STORIES\\nAim: To provide an opportunity for Ss to develop their research and collaboration skills, and to practise giving an oral presentation.\\n•\\tAs Ss have prepared for the project throughout the unit, the focus of this lesson should be on the final product, which is a presentation of a visual story.\\n•\\tHave Ss work in their groups. Give them a few minutes to get ready for the presentation.\\n•\\tGive Ss checklists for peer and self-assessment. Explain that they will have to tick appropriate items while listening to their classmates’ presentation or viewing their posters/comic strips, and write comments if they have any. The presenters or group representatives should complete their self-assessment checklist after completing their presentation or after answering all the questions about their posters/comic strips.\\n•\\tIf necessary, go through the assessment criteria to make sure Ss are familiar with them.\\n•\\tIf most Ss are giving poster presentations or designing comic strips, organise an exhibition in the classroom where each group can display their posters or comic strips in advance. Then have Ss walk around, view the posters or comic strips, and ask questions about them.\\n•\\tYou can also give Ss marks for their posters/comic strips and presentations as part of their continuous assessment.\\n•\\tEncourage Ss to reflect on their performance and think about what they could have done better.\\nSuggested checklist for peer assessment:\\n|  | Tick where appropriate | Comments (in English or Vietnamese) |\\n|---|---|---|\\n| DELIVERY |   |  |\\n| - The group representative(s) spoke clearly and naturally. |   |  |\\n| - The group representative(s) explained the visual story well. |   |  |\\n| - The group representative(s) answered all questions. |   |  |\\n| CONTENT |   |  |\\n| - the person’s name |   |  |\\n| - key events in his/her life |   |  |\\n| - his/her achievements |   |  |\\n| - your opinion about the person |   |  |\\n| DESIGN/ORGANISATION |   |  |\\n| - The visual story is well-organised. |   |  |\\n| - It is visually attractive and includes appropriate images. |   |  |\\n| - There are no spelling or grammar mistakes. |   |  |\\nSuggested checklist for self-assessment:\\n|  | Tick where appropriate | Comments (in English or Vietnamese) |\\n|---|---|---|\\n| DELIVERY |   |  |\\n| - I spoke clearly and naturally. |   |  |\\n| - I explained the visual story well. |   |  |\\n| - I answered all questions. |   |  |\\n| CONTENT |   |  |\\n| - the person’s name |   |  |\\n| - key events in his/her life |   |  |\\n| - his/her achievements |   |  |\\n| - your opinion about the person |   |  |\\n| DESIGN/ORGANISATION |   |  |\\n| - The visual story is well-organised. |   |  |\\n| - It is visually attractive and includes appropriate images. |   |  |\\n| - There are no spelling or grammar mistakes. |   |  ||\\n| Things I could have done better\\nNOW I CAN ...\\nFinally, ask Ss to complete the self-assessment table. Identify any difficulties and weak areas, and provide further practice.', 'metadata': {'page': '26', 'chunk_type': 'activity', 'related_chunks': 'unit_1_page_19_3', 'id': 'unit_1_page_26_2', 'unit': 'Life stories we admire', 'section': 'PROJECT'}}\n",
      "{'id': 'unit_1_page_14_1', 'unit': 'Life stories we admire', 'section': 'LANGUAGE', 'type': 'list', 'content': 'ACTIVITY 2\\nAim: To help Ss practise the past simple and the past continuous in a speaking activity.\\n•\\tAsk Ss to work in pairs. Explain that they will take turns to tell the life stories of people they know and admire. They should make 3–5 sentences, using the past simple and past continuous as much as they can.\\n•\\tEncourage them to study the example first. Tell them to pay attention to the use of the past simple and past continuous.\\n•\\tEncourage Ss to brainstorm some ideas in pairs and plan their life stories. In weaker classes, write some life events as prompts on the board and have Ss write their sentences first before reading them to each other.\\n•\\tGive Ss enough time to work in pairs, then invite some pairs to tell their life stories or read their sentences aloud in front of the class. Praise Ss for using the past simple and past continuous correctly.\\nSuggested answer:\\nWhen the war **started**, my grandfather **was enjoying** a happy life and marriage with my grandmother. Then he **left** his home town to join the army. When he **was fighting** in the war, my grandmother **was taking care of** the whole family. While he **was serving** in the army, he **was awarded** a medal for bravery.\\nExtension: Have Ss play a game of alibi (evidence that proves someone was not where a crime happened). Make up any story that something was stolen from a school party at 6 p.m. last night. Divide the class into policemen and suspects, then put Ss into groups of four: two policemen and two suspects. Have the policemen write down questions they want to ask the suspects while the suspects decide on answers to any possible questions. Then once they are ready, the policemen interview the suspects separately. The two suspects in each group must give the same answers. If they don’t, they are likely to be the thieves. In weaker classes, write some prompts on the board, e.g. *where/when you met, what you were doing at 6 p.m., what you heard/noticed*.', 'metadata': {'page': '14', 'chunk_type': 'activity', 'related_chunks': 'unit_1_page_11_2', 'id': 'unit_1_page_14_1', 'unit': 'Life stories we admire', 'section': 'LANGUAGE'}}\n",
      "{'id': 'unit_1_page_19_2', 'unit': 'Life stories we admire', 'section': 'LISTENING', 'type': 'list', 'content': 'ACTIVITY 3. While-listening\\nAim: To help Ss practise listening for specific information.\\n•\\tTell Ss that they are going to listen to the recording again. This time, they should complete a multiple-choice activity by choosing the correct answer A, B, or C.\\n•\\tHave them read the questions and answer choices, and underline keywords. In weaker classes, check understanding of the vocabulary.\\n•\\tPlay the recording and ask Ss to listen and pay attention to the keywords, as well as their paraphrases.\\n•\\tRemind them that they should watch out for distractors, especially options that may be mentioned on the recording, but are not true.\\n•\\tFor Question 3, remind them that they should choose information NOT mentioned on the recording. To do that Ss should try to eliminate the two options that match the information on the recording. The remaining option is the correct answer.\\n•\\tIn weaker classes, play the recording a second time pausing at places where Ss can find the answers.\\n•\\tCheck answers as a class.\\nKey: 1. B\\t2. A\\t3. C\\t4. B\\t5. B\\nAudio script – Tracks 4 + 5:\\nWalt Disney was one of the most admired people in the film industry. Many of the films created by his company are very popular with both children and adults.\\nHowever, success did not come early for Disney. When he set up his own film company, it was not very profitable. So Disney chose to move to Hollywood to start a new career.\\nThere, he developed a character based on a pet mouse he once had, under the name of Mickey Mouse. He even gave the mouse his own voice. Soon, Mickey Mouse became the world’s most popular cartoon character and Disney was very popular worldwide.\\nBut Disney did not stop there. He went on to produce his first feature-length animated film *Snow White and the Seven Dwarfs*. The film became a huge success, earning more than 400 million dollars since its release and eight Oscars, the top award in the film industry. Throughout his career, Disney won or received 26 Oscars – a record in history.\\nBesides making films, Disney was also the creator of the first Disneyland theme park which opened in 1955. Nowadays, there are 12 Disney parks around the world where people can meet Disney cartoon characters and see live shows of their magical stories.\\nAfter his death, The Walt Disney Studios continued to make high-quality live-action and animated films, such as *The Little Mermaid, Beauty and the Beast,* and *The Lion King*. His films continue to inspire both adults and children to follow their dreams.\\nExtension: Ask some additional questions to check Ss’ comprehension of other details in the listening text, e.g. *Who are his films popular with?* (both children and adults) *How much money did his first film company make?* (Not much, it was not very profitable.).', 'metadata': {'page': '19', 'chunk_type': 'activity', 'related_chunks': 'unit_1_page_15_2', 'id': 'unit_1_page_19_2', 'unit': 'Life stories we admire', 'section': 'LISTENING'}}\n",
      "{'id': 'unit_1_page_24_1', 'unit': 'Life stories we admire', 'section': 'COMMUNICATION AND CULTURE / CLIL', 'type': 'list', 'content': 'CULTURE/CLIL\\nQUEENS OF THE WORLD\\nACTIVITY 1\\nAim: To help Ss learn about the lives of three famous queens in world history.\\n•\\tAsk Ss some questions to find out what they already know about the topic, e.g. *Do you know the names of the people in the pictures? Who are they? What made them famous?*\\n•\\tAsk Ss what they want to know about the topic. Write their questions on the board, e.g. *Where were they from? (Egypt, England, and Russia), In which period/era did they live? (69 BC–30 BC, 1533–1603, 1729–1796).*\\n•\\tAsk Ss to study the comparison table. Make sure they understand how the information is organised in rows and columns. Encourage them to study the examples.\\n•\\tTell Ss that they are going to read a text about the three queens. As they read, they should fill in the table to find the similarities and differences between their lives and achievements.\\n•\\tExplain or elicit any new or difficult words, e.g. *determination, Empire, rule/ruling*. In stronger classes, encourage them to guess their meaning from context as they read the text.\\n•\\tHave Ss read the text and complete the table individually.\\n•\\tCheck answers as a class.\\n•\\tGo back to the questions on the board, i.e. the things Ss wanted to know about the topic. Ask which of the questions they can answer now and cross them out. Assign the rest for homework.\\nSuggested answer:\\n|  | Cleopatra VII | Elizabeth I | Catherine II |\\n|---|---|---|---|\\n| Country | Egypt | (1) England | (2) Russia |\\n| Years of being queen | (3) 21 | 45 | (4) 34 |\\n| Characteristics | determined, intelligent | determined, intelligent | intelligent, ambitious |\\n| Achievements | (5) saved her country from becoming part of the expanding Roman Empire | (6) defeated the powerful Spanish Navy; encouraged the development of the arts | expanded the Russian Empire; improved education for children and women; encouraged great developments in architecture, trade, and culture |', 'metadata': {'page': '24', 'chunk_type': 'activity', 'related_chunks': 'unit_1_page_17_3', 'id': 'unit_1_page_24_1', 'unit': 'Life stories we admire', 'section': 'COMMUNICATION AND CULTURE / CLIL'}}\n",
      "{'id': 'unit_1_page_21_3', 'unit': 'Life stories we admire', 'section': 'WRITING', 'type': 'list', 'content': 'ACTIVITY 3\\nAims:\\n– To help Ss synthesise and summarise information from two different sources;\\n– To help Ss practise writing a biography of Walt Disney.\\n•\\tTell Ss that they are going to write a 180-word biography of Walt Disney. They should use the information they have collected to answer the questions in **1**. They can also select any other facts from **2**.\\n•\\tAsk them to study the outline first. In weaker classes, ask some prompt questions to help them work out what information they need to include in each part of the biography, e.g. *What should we write in the ‘Childhood and education’ section? (information about his birthday/birthplace and the school he went to).*\\n•\\tGive Ss a time limit. In weaker classes, put Ss in pairs or groups to help each other. Walk round the class to provide help when necessary.\\n•\\tIn stronger classes, have Ss work individually, then swap their drafts with a partner and comment on each other’s ideas, vocabulary, and grammar. If time allows, encourage Ss to make revisions based on peer feedback before they produce a final draft.\\n•\\tCollect Ss’ biographies and give face-to-face feedback in private, or give them back with some written feedback.\\nSuggested answer:\\nWALT DISNEY – THE FATHER OF MICKEY MOUSE\\nWalt Disney is famous around the world for making a lot of successful films, which are loved by children and adults of many generations.\\nChildhood and education\\nWalt Disney was born in Chicago in 1901. During his childhood, he loved drawing and painting. He attended Brenton Grammar School, but he left school when he was 16.\\nAchievements\\nDisney was a very successful film-maker, who created Mickey Mouse and produced successful animated films such as *Snow White and the Seven Dwarfs*. Throughout his career, Disney won or received 26 Oscars, three Golden Globe Awards, one Emmy Award – a record in history.\\nHe was famous for building the first theme park in the world, called Disneyland. Now many more Disney parks have been built and have become popular worldwide.\\nFamily\\nWalt Disney had three older brothers and a younger sister. He married Lillian Bounds, and they were together for 41 years. They had one biological daughter and one adopted daughter.\\nDeath and the continued success of The Walt Disney Studios\\nDisney died from cancer in 1966, but The Walt Disney Studios continued to make live-action and animated films. These films inspire people of all ages to follow their dreams.', 'metadata': {'page': '21', 'chunk_type': 'activity', 'related_chunks': 'unit_1_page_16_1', 'id': 'unit_1_page_21_3', 'unit': 'Life stories we admire', 'section': 'WRITING'}}\n",
      "{'id': 'page_3_1', 'unit': None, 'section': None, 'type': 'text', 'content': 'LỜI NÓI ĐẦU\\n\\nTiếng Anh 12 – Global Success – Sách học sinh được Nhà xuất bản Giáo dục Việt Nam\\ntổ chức biên soạn theo “Chương trình giáo dục phổ thông: Chương trình môn Tiếng Anh”\\n(từ lớp 3 đến lớp 12) ban hành theo Thông tư 32/2018/TT-BGDĐT ngày 26 tháng 12 năm 2018\\ncủa Bộ Giáo dục và Đào tạo, nối tiếp bộ sách tiếng Anh bậc tiểu học (Tiếng Anh 3, Tiếng Anh\\n4, Tiếng Anh 5), bộ sách tiếng Anh trung học cơ sở (Tiếng Anh 6, Tiếng Anh 7, Tiếng Anh 8,\\nTiếng Anh 9), Tiếng Anh 10 và Tiếng Anh 11.\\n\\nTiếng Anh 12 – Global Success – Sách học sinh được biên soạn theo đường hướng\\ngiao tiếp, giúp học sinh phát triển năng lực giao tiếp bằng tiếng Anh dưới bốn hình\\nthức nghe, nói, đọc, viết thông qua sử dụng ngữ liệu (ngữ âm, từ vựng, ngữ pháp). Đồng\\nthời, sách được biên soạn theo đường hướng lấy người học làm trung tâm, theo đó mọi\\nhoạt động dạy học được thiết kế và tổ chức đều nhằm phát huy tính tích cực, chủ động\\ncủa học sinh và tạo điều kiện tối đa cho học sinh tham gia vào các hoạt động luyện tập và\\nphát triển năng lực giao tiếp tiếng Anh.\\n\\nTiếng Anh 12 – Global Success – Sách học sinh được biên soạn theo hướng tích hợp\\ncác kĩ năng, theo đó các kĩ năng đọc, nói, nghe, viết bổ trợ cho nhau và được phát triển\\nxoay quanh bốn chủ điểm (Theme) gần gũi với học sinh: Cuộc sống của chúng ta (Our Lives),\\nXã hội của chúng ta (Our Society), Môi trường của chúng ta (Our Environment) và Tương lai\\ncủa chúng ta (Our Future). Bốn chủ điểm này được cụ thể hoá thành mười đơn vị bài học\\n(Unit), mỗi đơn vị bài học tương ứng với một chủ đề (Topic). Sau mỗi số chủ đề là một\\nbài ôn tập (Review), tập trung vào rèn luyện kiến thức ngôn ngữ và phát triển kĩ năng\\nngôn ngữ học sinh đã được học.\\n\\nTiếng Anh 12 – Global Success – Sách học sinh coi trọng đặc điểm tâm lí lứa tuổi của\\nhọc sinh và các đặc điểm văn hoá của Việt Nam, của các nước nói tiếng Anh và của các\\nnước trên thế giới. Ngoài ra, Tiếng Anh 12 – Global Success – Sách học sinh còn được\\nbiên soạn theo hướng giúp bổ sung, làm giàu thêm kiến thức nền của học sinh về một số\\nlĩnh vực khoa học và đời sống xã hội.\\n\\nTiếng Anh 12 – Global Success – Sách học sinh được biên soạn dựa trên cơ sở lí luận\\nhiện đại về biên soạn sách giáo khoa ngoại ngữ trên thế giới, đặc biệt là những kinh nghiệm\\nthực tiễn của việc dạy tiếng Anh cấp trung học phổ thông ở Việt Nam, với sự hợp tác\\nchặt chẽ về chuyên môn và kĩ thuật của Tập đoàn xuất bản Giáo dục Pearson.\\n\\nNhóm tác giả rất mong nhận được những ý kiến đóng góp của các em học sinh,\\ncác nhà giáo, các bậc phụ huynh và đông đảo bạn đọc quan tâm để sách được hoàn thiện hơn.\\n\\nCác tác giả', 'metadata': {'page': '3', 'chunk_type': 'paragraph', 'related_chunks': '', 'id': 'page_3_1', 'unit': None, 'section': None}}\n",
      "Total chunks: 79\n",
      "Average tokens per chunk: 250.66\n",
      "Max tokens: 870\n",
      "Min tokens: 23\n"
     ]
    }
   ],
   "source": [
    "# ... existing code ...\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def analyze_token_count(text, tokenizer):\n",
    "    \"\"\"\n",
    "    Analyze token count for a given text.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to analyze\n",
    "        tokenizer: HuggingFace tokenizer instance\n",
    "        \n",
    "    Returns:\n",
    "        int: Number of tokens\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "def load_and_process_json(json_path, tokenizer=None):\n",
    "    \"\"\"\n",
    "    Load a JSON file and process its content to extract text data.\n",
    "    \n",
    "    Args:\n",
    "        json_path (str): Path to the JSON file.\n",
    "        tokenizer: Optional tokenizer for token count analysis\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of Document objects containing processed text and metadata.\n",
    "    \"\"\"\n",
    "    # Load JSON data\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    for item in data:\n",
    "        content = item.get(\"content\", \"\")\n",
    "        unit_info = f\"Unit: {item.get('unit')}\" if item.get('unit') else \"\"\n",
    "        section_info = f\"Section: {item.get('section')}\" if item.get('section') else \"\"\n",
    "        type_info = f\"Type: {item.get('type')}\" if item.get('type') else \"\"\n",
    "        enriched_text = f\"{unit_info}\\n{section_info}\\n{type_info}\\n{content}\".strip()\n",
    "        \n",
    "        metadata = item.get(\"metadata\", {})\n",
    "        metadata.update({\n",
    "            \"id\": item.get(\"id\"),\n",
    "            \"unit\": item.get(\"unit\"),\n",
    "            \"section\": item.get(\"section\"),\n",
    "        })\n",
    "        \n",
    "        # Add token count to metadata if tokenizer is provided\n",
    "        if tokenizer:\n",
    "            token_count = analyze_token_count(enriched_text, tokenizer)\n",
    "            if token_count > 512:\n",
    "                print(item)\n",
    "            metadata[\"token_count\"] = token_count\n",
    "            \n",
    "        # Create a Document object\n",
    "        doc = Document(text=enriched_text, metadata=metadata)\n",
    "        documents.append(doc)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "def process_all_json_files(directory, tokenizer):\n",
    "    \"\"\"\n",
    "    Process all JSON files in the specified directory.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): Path to the directory containing JSON files.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of Document objects from all processed JSON files.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            documents.extend(load_and_process_json(file_path, tokenizer))\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Example usage:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"intfloat/multilingual-e5-small\")\n",
    "documents = process_all_json_files(json_dir, tokenizer)\n",
    "\n",
    "# Analyze token distribution\n",
    "token_counts = [doc.metadata[\"token_count\"] for doc in documents]\n",
    "print(f\"Total chunks: {len(token_counts)}\")\n",
    "print(f\"Average tokens per chunk: {sum(token_counts)/len(token_counts):.2f}\")\n",
    "print(f\"Max tokens: {max(token_counts)}\")\n",
    "print(f\"Min tokens: {min(token_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
